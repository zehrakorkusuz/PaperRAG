# Retriever Modules Overview

This repository contains different retriever classes designed for information retrieval from a collection of documents. The retrievers use various techniques, including **sparse retrieval** (BM25) and **dense retrieval** (embedding-based). The system is designed to handle text, image, and potentially other modalities for cross-modality retrieval.

## 1. **BM25 Retriever (`BM25Retriever`)**

The `BM25Retriever` is a sparse retrieval system based on the **BM25** algorithm, a popular probabilistic information retrieval model. It ranks documents based on term frequency and inverse document frequency (TF-IDF).

### Key Features:
- **Preprocessing**: Text is preprocessed by converting it to lowercase, removing punctuation, and splitting into tokens.
- **Fallback Strategy**: For small corpora (where the number of documents is below a specified threshold), the retriever switches to **Jaccard Similarity**. This is used to prioritize partial matches between the query and documents.
- **BM25 Retrieval**: For larger corpora, the BM25 algorithm is used to compute scores for documents based on the query.

### Additional Strategies:
- **Jaccard Similarity Fallback**: If the number of documents is small, Jaccard Similarity is used to calculate the similarity between query tokens and document tokens. This approach prioritizes partial matches when the document corpus is small.

## 2. **Hybrid Retriever (`HybridRetriever`)**

The `HybridRetriever` combines both **sparse retrieval (BM25)** and **dense retrieval (embedding-based)** for more accurate results. It can process both text and image queries.

### Key Features:
- **Sparse Retrieval**: Uses a BM25-based sparse retriever to retrieve relevant documents.
- **Dense Retrieval**: Uses a dense retriever (based on embeddings) for both text and image modalities.
- **Normalization**: **Z-score normalization** is applied to the scores from both sparse and dense retrievals, ensuring that they are on a similar scale.
- **Weighted Combination**: Sparse and dense scores are combined using specified weights to compute the final result ranking.

### Additional Strategies:
- **Z-score Normalization**: This strategy ensures that the sparse and dense scores are comparable by transforming them to have a mean of 0 and a standard deviation of 1. Z-score normalization handles outliers better and makes the scores scale-independent, making it suitable for cross-modality search.
- **Weighted Combination**: Both sparse and dense results are combined using weighted scores to provide a unified ranking of results. The weights can be adjusted based on the desired contribution of sparse and dense retrieval in the final score.

## 3. **Dense Retriever (`DenseRetriever`)**

The `DenseRetriever` is responsible for dense retrieval using embeddings generated by an embedding model. It retrieves the top-K results based on the vector similarities between the query vector and the document vectors stored in a vector database.

### Key Features:
- **Embedding Models**: Supports text and image modalities by generating respective embeddings.
- **Vector Database**: Stores the document embeddings in a vector database and performs efficient similarity search.
- **Modality Support**: Can handle different modalities (text, image) and retrieve the most similar documents based on the query embedding.

## 4. **Embedding Models and Vector Database**

- **Embedding Models**: Used to generate embeddings for both text and images. These embeddings are later used for dense retrieval.
- **Vector Database**: Stores and retrieves document vectors based on their similarity to the query vector.

## Installation

To use the retrievers, you need to have the following dependencies installed:

```python
pip install numpy rank_bm25

from retrievers.dense_retriever import DenseRetriever
from retrievers.sparse_retriever import BM25Retriever
from retrievers.hybrid_retriever import HybridRetriever

# Initialize retrievers
sparse_retriever = BM25Retriever(documents)
dense_retriever = DenseRetriever(embedding_model, vector_db)
hybrid_retriever = HybridRetriever(sparse_retriever, dense_retriever)

# Perform retrieval
results = hybrid_retriever.retrieve(query_text="Find documents related to machine learning", top_k=5)
for score, meta in results:
    print(f"Score: {score}, Document: {meta['text']}")
```